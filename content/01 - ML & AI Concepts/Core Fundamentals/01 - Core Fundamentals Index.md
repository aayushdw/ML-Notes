# 01 - Core Fundamentals

## Overview
Mastering the foundational concepts of Machine Learning and Deep Learning. These are the building blocks that underpin all modern AI systems.

---

## ðŸŽ¯ Machine Learning Basics

### Learning Paradigms
- [x] [[Supervised Learning]]
- [ ] [[Unsupervised Learning]]
- [ ] [[Reinforcement Learning]]
- [ ] [[Semi-Supervised Learning]]
- [ ] [[Self-Supervised Learning]]

### Model Training & Evaluation
- [ ] [[Model Training Fundamentals]]
- [ ] [[Training vs Validation vs Test Sets]]
- [ ] [[Cross-Validation]]
- [ ] [[Overfitting and Underfitting]]
- [ ] [[Regularization Techniques]]
- [ ] [[Bias-Variance Tradeoff]]

### Feature Engineering
- [ ] [[Feature Engineering Principles]]
- [ ] [[Feature Selection Methods]]
- [ ] [[Feature Scaling and Normalization]]
- [ ] [[Dimensionality Reduction]]
- [ ] [[PCA (Principal Component Analysis)]]

### Evaluation Metrics
- [x] [[Regression Metrics]]
- [x] [[Precision, Recall, and F1-Score]]
- [x] [[ROC Curves and AUC]]

---

## ðŸ§  Deep Learning Architecture

### Neural Network Fundamentals
- [ ] [[Neural Networks Basics]]
- [ ] [[Perceptron and Multi-Layer Perceptron]]
- [ ] [[Activation Functions]]
- [ ] [[Backpropagation]]
- [ ] [[Gradient Descent and Optimization]]
- [ ] [[Batch, Mini-Batch, and Stochastic Gradient Descent]]

### Optimization Algorithms
- [ ] [[SGD (Stochastic Gradient Descent)]]
- [ ] [[Momentum]]
- [ ] [[Adam Optimizer]]
- [ ] [[RMSprop]]
- [ ] [[Learning Rate Scheduling]]

### Convolutional Neural Networks
- [ ] [[CNN Fundamentals]]
- [ ] [[Convolution Operations]]
- [ ] [[Pooling Layers]]
- [ ] [[CNN Architectures Overview]]
- [ ] [[ResNet Architecture]]
- [ ] [[VGG Architecture]]
- [ ] [[Inception Networks]]

### Recurrent Neural Networks
- [ ] [[RNN Fundamentals]]
- [ ] [[LSTM (Long Short-Term Memory)]]
- [ ] [[GRU (Gated Recurrent Unit)]]
- [ ] [[Vanishing and Exploding Gradients]]
- [ ] [[Bidirectional RNNs]]

### Transformer Architecture
- [ ] [[Transformer Architecture Overview]]
- [ ] [[Self-Attention Mechanism]]
- [ ] [[Multi-Head Attention]]
- [ ] [[Positional Encoding]]
- [ ] [[Encoder-Decoder Architecture]]
- [ ] [[Vision Transformers (ViT)]]

### Modern Architectures
- [ ] [[Attention Mechanisms in Deep Learning]]
- [ ] [[Residual Connections]]
- [ ] [[Batch Normalization]]
- [ ] [[Layer Normalization]]
- [ ] [[Dropout and Regularization]]

---

## ðŸ“Š Progress Tracking

```dataview
TABLE
  status as "Status",
  difficulty as "Difficulty",
  last_modified as "Last Updated"
FROM "01 - ML & AI Concepts/01 - Core Fundamentals"
WHERE contains(tags, "concept")
SORT file.name ASC
```

---

## ðŸŽ“ Learning Path

**Recommended Order:**
1. Start with Machine Learning Basics â†’ Learning Paradigms
2. Understand Model Training & Evaluation
3. Learn Neural Network Fundamentals
4. Study Optimization Algorithms
5. Master CNNs and RNNs
6. Finally, dive into Transformers

---

**Back to**: [[ML & AI Index]]
